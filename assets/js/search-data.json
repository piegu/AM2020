{
  
    
        "post0": {
            "title": "Neural Networks A Brief History",
            "content": "Fonte: tradução automática por Google Docs de “Your deep learning journey” do livro Fastai (Jeremy Howard e Sylvain Gugger). . Modelo matemático de um neurônio artificial . Em 1943, Warren McCulloch, um neurofisiologista, e Walter Pitts, um lógico, se uniram para desenvolver um modelo matemático de um neurônio artificial. Eles declararam que: . Devido ao caráter “tudo ou nada” da atividade nervosa, os eventos neurais e as relações entre eles podem ser tratados por meio da lógica proposicional. Verifica-se que o comportamento de toda rede pode ser descrito nesses termos. (Pitts e McCulloch; Um cálculo lógico das idéias imanentes à atividade nervosa) . Eles perceberam que um modelo simplificado de um neurônio real poderia ser representado usando adição e limiares simples, como mostrado aqui: . . O Perceptron: a capacidade de aprender . Frank Rosenblatt ainda mais( 1956) desenvolveu o neurônio artificial para lhe dar a capacidade de aprender. Mais importante ainda, ele trabalhou na construção do primeiro dispositivo que realmente usava esses princípios: o Mark I Perceptron. . Rosenblatt escreveu sobre este trabalho: “estamos prestes a testemunhar o nascimento de tal máquina - uma máquina capaz de perceber, reconhecer e identificar seu entorno sem nenhum treinamento ou controle humano”. O perceptron foi construído e conseguiu reconhecer formas simples. . Perceptrons: início do primeiro inverno da IA . Um professor do MIT chamado Marvin Minsky (que ficou atrás de Rosenblatt na mesma escola!) Junto com Seymour Papert escreveu um livro, chamado “Perceptrons”, sobre a invenção de Rosenblatt. Eles mostraram que uma única camada desses dispositivos não conseguiu aprender algumas funções matemáticas simples e críticas (como o XOR). . No mesmo livro, eles também mostraram que o uso de várias camadas dos dispositivos permitiria resolver essas limitações. Infelizmente, apenas a primeira dessas idéias foi amplamente reconhecida, como resultado da comunidade acadêmica global quase inteiramente desistindo de redes neurais pelas próximas duas décadas. . Redes neurais . Talvez o trabalho mais crucial em redes neurais nos últimos 50 anos seja ovários volumes Processamento Distribuído Paralelo (PDP) de, lançado em 1986 pela MIT Press. Capítulo 1 estabelece uma esperança semelhante ao mostrado por . Rosenblatt:: … as pessoas são mais espertos do que os computadores de hoje porque o cérebro emprega uma arquitetura computacional básico que é mais adequado para lidar com um aspecto central das informações naturais processamento de tarefas que as pessoas são tão bons às. … introduziremos uma estrutura computacional para modelar processos cognitivos que parece … mais próxima do que outras estruturas ao estilo de computação, como pode ser feito pelo cérebro. (PDP, capítulo 1) . A premissa que o PDP está usando aqui é que os programas de computador tradicionais funcionam de maneira muito diferente dos cérebros, e pode ser por isso que os programas de computador (naquele momento) foram tão ruins em fazer coisas que os cérebros acham fáceis (como reconhecer objetos nas fotos). Os autores afirmam que a abordagem PDP é “mais próxima do que outras estruturas” de como o cérebro funciona e, portanto, pode ser mais capaz de lidar com esse tipo de tarefa. . De fato, a abordagem apresentada no PDP é muito semelhante à usada nas redes neurais atuais. O livro definia “Processamento Distribuído Paralelo” como exigindo: . Um conjunto dede unidadesprocessamento . | Um estado de ativação . | Uma função de saída para cada unidade . | Um padrão de conectividade entre unidades . | Uma regra de propagação para propagar padrões de atividades através da rede de conectividades . | Uma regra de ativação para combinar as entradas que colidem com uma unidade com o estado atual dessa unidade para produzir um novo nível de ativação para a unidade. . | Uma regra de aprendizado segundo a qual os padrões de conectividade são modificados pela experiência. . | Um ambiente no qual o sistema deve operar. . | Veremos neste livro que redes neurais lidam com cada um desses requisitos. . Década de 1980: primeiras aplicações de NN . Na década de 1980, a maioria dos modelos foi construída com uma segunda camada de neurônios, evitando assim o problema identificado por Minsky (esse era seu “padrão de conectividade entre unidades”, para usar a estrutura acima). E, de fato, as redes neurais foram amplamente usadas nas décadas de 80 e 90 para projetos reais e práticos. No entanto, novamente um equívoco das questões teóricas impediu o campo. Em teoria, adicionar apenas uma camada extra de neurônios era suficiente para permitir que qualquer modelo matemático se aproximasse dessas redes neurais, mas, na prática, essas redes eram muitas vezes grandes e lentas demais para serem úteis. . Mais camadas! . Embora os pesquisadores tenham mostrado há 30 anos que, para obter um bom desempenho prático, você precisa usar ainda mais camadas de neurônios, é apenas na última década que isso tem sido mais amplamente apreciado. As redes neurais estão finalmente alcançando seu potencial, graças ao entendimento de usar mais camadas e à capacidade aprimorada de fazê-lo, graças a melhorias no hardware do computador, aumentos na disponibilidade de dados e ajustes algorítmicos que permitem que as redes neurais sejam treinadas mais rapidamente e mais facilmente. . Agora temos o que Rosenblatt havia prometido: “uma máquina capaz de perceber, reconhecer e identificar seu entorno sem nenhum treinamento ou controle humano”. .",
            "url": "https://piegu.github.io/AM2020/2020/03/12/neural-networks-a-brief-history.html",
            "relUrl": "/2020/03/12/neural-networks-a-brief-history.html",
            "date": " • Mar 12, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . Front Matter is a markdown cell at the beginning of your notebook that allows you to inject metadata into your notebook. For example: . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . More detailsssssss and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks just like you can with markdown. . For example, here is a footnote 1. . . This is the footnote.&#8617; . |",
            "url": "https://piegu.github.io/AM2020/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Test Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://piegu.github.io/AM2020/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "Sobre mim",
          "content": "Por sua capacidade de aumentar o potencial humano em muitas áreas, a Inteligência Artificial (IA) altera o papel do ser humano na sociedade com impactos sociais e econômicos muito significativos. Para se preparar para essas mudanças, precisamos de mais cientistas da computação treinados para desenvolver aplicativos de IA, de mais intervenientes que podem definir um quadro ético no uso da IA e de mais profissionais que podem acompanhar a transformação das empresas. . Desde 2016, para contribuir para este triplo objetivo (técnico, ético e de negócio), lançei com outras pessoas várias iniciativas em IA em Brasília: . formação às técnicas de IA: meetup Deep Learning Brasília e Grupo de Estudo do DL em Brasília | palestras e cursos sobre a ética na IA e a IA nos negócios: meetup Inteligência Artificial Brasília | papeis e conferências sobre a IA, o Machine Learning e o Deep Learning (medium.com/@pierre_guillou) | . Sou também: . Consultor em Inteligência Artificial e Deep Learning e trabalha para nama.ai como Lead AI Scientist | Pesquisador Associado ao Laboratório de Inteligência Artificial (AI.Lab) da Faculdade UnB Gama (FGA) | Professor vinculado ao curso de Machine Learning e Deep Learning da Faculdade UnB Gama (FGA) | . Anteriormente, trabalhei principalmente no campo da comunicação digital e acessibilidade à Internet. . Mais informações sobre mim (Pierre Guillou) no meu perfil Linkedin. .",
          "url": "https://piegu.github.io/AM2020/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  
      ,"page2": {
          "title": "Curso",
          "content": "Lição 1 (10/03/2020) - Apresentação da disciplina . Lição 2 (12/03/2020) - Apresentação geral da Inteligência Artificial e Responsabilidades . Redes neurais: uma breve história | .",
          "url": "https://piegu.github.io/AM2020/course/",
          "relUrl": "/course/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}